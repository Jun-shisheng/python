# Python数据分析与应用 第二版（微课版）
---
## 课后的实训题：
---
## 房屋销售数据统计分析 `3chapter.py`

### 1. 数据读取与基础操作
- 读取 CSV 文件，预览数据
- 查看数据的维度（`ndim`）、形状（`shape`）与列名
- 使用 `.iloc` 和 `.loc` 进行数据索引操作

### 2. 统计分析
- 对“房屋价格/元”字段计算：
  - 平均值（mean）、最大值（max）、最小值（min）
  - 众数（mode）、分位数（quantile）
  - 综合描述统计（`describe()`）

### 3. 特征工程
- 新增特征：`new_postcode`，提取“地区邮编”前四位作为地区标识
- 将“房屋出售时间”字段转换为时间格式（`to_datetime`）

### 4. 分组与聚合分析
- 使用 `groupby` 对“房屋类型”与 `new_postcode` 进行分组
- 计算分组后的房价均值（`transform('mean')`）

### 5. 数据透视与交叉表分析
- 使用 `pivot_table` 构建透视表，查看不同房屋类型在不同地区的平均房价
- 使用 `crosstab` 构建交叉表，统计各房屋类型与地区组合的频数分布（包含总计行/列）

---

## 病患数据分析 `4chapter.py`

### 1. 数据读取与合并
- 从 Excel 文件中读取两个数据集：
  - `healthcare-dataset-stroke.xlsx`（中风相关数据）
  - `healthcare-dataset-age_abs.xlsx`（补充年龄信息）
- 使用 `merge` 函数以“编号”为主键外连接合并两个数据集
- 重置索引保持数据连续性

### 2. 异常值处理
- 检查“年龄/岁”字段的值是否在合理范围（0 < 年龄 ≤ 120）
- 删除年龄为空或超出合理范围的记录
- 重置索引

### 3. 年龄离散化处理
- 自定义分箱区间：`[0, 20, 40, 60, 80, 120]`
- 对“年龄/岁”进行等宽离散化，使用 `pd.cut()` 方法
- 为每个年龄段添加标签（如："0-19岁", "20-39岁" 等）

### 4. 分段统计与输出
- 输出每个年龄区间的范围
- 显示处理后的数据集中的编号、年龄和年龄分段
- 统计每个年龄区间的人数，并以格式化方式打印

### 5. 数据导出
- 将处理后的完整数据保存为 Excel 文件：`data/merged_result.xlsx`
  
---

## 学生成绩分析与特征关系可视化 `5chapter1.py`

### 1. 数据读取与准备
- 从 `student_grade.xlsx` 读取学生成绩数据集
- 设置 matplotlib 中文显示（黑体）、避免负号乱码

### 2. 成绩分段与分布统计
- 使用 `pd.cut` 对“总成绩”进行分箱：
  - 区间设置为 `[0, 150, 200, 250, 300]`
  - 标签设为：`['不及格', '及格', '良好', '优秀']`
- 添加新列“总成绩区间”
- 使用 `value_counts()` 统计各成绩段人数

### 3. 成绩分布可视化
#### 饼图展示成绩分布
- 使用 `pandas.Series.plot.pie()` 绘制饼图
- 配色包括淡红、淡蓝、浅绿色
- 设置 `explode` 增强视觉突出度
- 保持比例 (`axis('equal')`)

#### 箱线图展示单科成绩分布
- 对“数学成绩”、“阅读成绩”、“写作成绩”绘制箱线图
- 使用 seaborn `boxplot()` 进行可视化
- 显示均值点（红边白心圆），观察中位数、异常值等统计特征

### 4. 特征与总成绩关系分析
#### 自我效能感影响
- 使用 `groupby` 和 `mean()` 计算不同“自我效能感”水平下的总成绩均值
- 绘制柱状图展示三类效能感（低、中、高）对应平均总成绩差异

#### 课程准备情况影响
- 计算完成/未完成准备下的平均总成绩差异
- 使用柱状图可视化准备与否对成绩的影响
- 柱顶标注均值（保留一位小数）

### 5. 分析结果输出
- 打印不同自我效能感的平均总成绩
- 计算并输出准备情况对平均成绩的提升幅度（例如：“完成准备的学生比未完成的平均高 X 分”）

---

## 空气质量分析与可视化 `5chapter2.py`

### 1. 数据读取与预处理
- 从 `aqi.csv` 读取空气质量数据，解析“日期”为时间格式
- 筛选出 2023 年 1 月至 9 月的数据进行分析

### 2. 空气质量等级可视化
#### 散点图（按质量等级分类）
- 使用 seaborn 绘制 AQI 指数随时间变化的散点图
- 按“质量等级”着色（绿色：优，蓝色：良，橙色：轻度污染，红色：中度污染，紫色：重度污染）
- 图例清晰标注各等级

### 3. PM2.5 与 AQI 的线性关系分析
- 提取 `PM2.5含量/ppm` 与 `AQI` 列，使用 NumPy 进行线性拟合
  - 计算线性方程：`y = slope * x + intercept`
  - 求出决定系数 `R²` 与 Pearson 相关系数
- 绘制拟合散点图与红色回归线，叠加 `R²` 与相关系数文本信息

### 4. 空气质量指标相关性分析
#### 热力图可视化
- 选择指标列：`AQI`、`PM2.5`、`PM10`、`SO2`、`CO`、`NO2`、`O3`
- 使用 `df.corr()` 计算皮尔逊相关系数矩阵
- 使用 seaborn 热力图显示各污染物与 AQI 的相关程度，中心值为 0，颜色由蓝至红

### 5. 关键统计信息输出
- 输出 AQI 与 PM2.5 的均值
- 输出质量等级分布频数
- 输出各污染物与 AQI 的相关系数（按强度排序）

---

## 商品销售数据可视化分析 `5chapter3.py`

### 1. 数据读取与预处理
- 从 `商品销售数据.csv` 文件中读取数据并指定列名：
  - 包括“订单号”、“设备ID”、“应付金额”、“实际金额”、“商品”、“支付时间”、“地点”、“状态”、“提现”、“大类”、“二级类”
- 将“实际金额”转换为数值类型，删除缺失值行以保证数据质量

### 2. 销售统计分析
#### 1）按“二级类”统计销售额总和，并降序排列
- 提取销售额前 5 的商品类别作为重点分析对象

#### 2）按“商品”名称统计销量频数
- 生成商品热度分布数据，适用于词云图展示

### 3. 数据可视化
#### 漏斗图：前5大销售额商品类别
- 使用 pyecharts 绘制漏斗图
- 图中展示每个类别对应的销售额，按金额递减排序
- 鼠标悬停可显示详细信息

#### 词云图：商品销量分布
- 商品名称作为关键词，销量作为权重绘制词云图
- 设置字体范围 `[12, 60]`，采用圆形布局增强美观性

### 4. 图表导出
- 漏斗图保存为 `data/sales_funnel.html`
- 词云图保存为 `data/product_wordcloud.html`

---

## 使用sklearn处理竞标行为数据集 `6chapter1.py`

### 1. 数据读取与初步查看
- 读取 `shill_bidding.csv` 数据集
- 初步查看数据结构与字段：
  - 包含“记录ID”、“拍卖ID”、“类别”等字段
  - “类别”为标签，其余为特征数据

### 2. 特征选择与数据划分
- 去除无关特征字段：“记录ID”、“拍卖ID”、“类别”以外的作为特征 X
- 将“类别”作为目标变量 y
- 使用 `train_test_split` 将数据按 80%：20% 比例划分为训练集和测试集

### 3. 特征标准化
- 采用 `MinMaxScaler` 进行特征归一化，将所有特征缩放至 \[0, 1\] 区间
- 分别对训练集和测试集进行标准化转换，防止数据泄露

### 4. 主成分分析（PCA）降维
- 使用 `sklearn.decomposition.PCA`，设置 `n_components=0.999` 以保留 99.9% 的信息量
- 对标准化后的训练集和测试集进行降维处理

### 5. 降维结果输出
- 显示降维前后数据维度变化：
  - 有助于了解特征压缩效果
  - 降低模型复杂度，提高后续分类器性能

---

## 构建基于竞标行为数据集的K-Means聚类模型 `6chapter2.py`

### 1. 数据读取与预处理
- 使用 Pandas 读取 `shill_bidding.csv` 数据，读取失败会抛出错误并终止程序
- 提取关键特征字段：
  - `"竞标者倾向"`、`"竞标比率"`、`"连续竞标"` 作为模型输入特征 `X`
  - `"类别"` 作为标签 `y`，并映射为二分类标签（0=正常，1=异常）

### 2. 数据集划分与标准化处理
- 使用 `train_test_split` 将数据划分为训练集（80%）与测试集（20%）
- 采用 `MinMaxScaler` 进行特征缩放，统一数据范围

### 3. PCA主成分分析降维
- 使用 `PCA(n_components=0.999)` 保留99.9%的信息量
- 降维处理后：
  - 显著减少特征维度，提高聚类计算效率
  - 降低维度带来的噪声干扰

### 4. 使用KMeans进行聚类
- 设置聚类数为2（假设正常/异常两类）
- 训练聚类模型，并获取训练集聚类标签

### 5. 聚类评估指标计算
- `adjusted_rand_score`（ARI）：调整兰德指数，衡量分类一致性
- `v_measure_score`：聚类结果的同质性与完整性平衡指标
- `fowlkes_mallows_score`（FMI）：衡量精确度与召回率的几何平均

### 6. 输出结果示例（直接运行调试会出现问题）
```text
Training set after PCA: (5056, 3)
Test set after PCA: (1265, 3)

For n_clusters = 2:
ARI评价指标: 0.8486263811782202
V-Measure评价指标: 0.7448523644108072
FMI评价指标: 0.9682949423300438
```
---

## 构建基于竞标行为数据集的支持向量机分类类型 `6chapter3.py`

### 1. 数据读取与特征准备
- 加载 `shill_bidding.csv` 数据集
- 去除无用字段 `"记录ID"` 和 `"拍卖ID"`
- 提取特征集 `X` 与标签列 `y = 类别`

### 2. 数据预处理
- 划分训练集与测试集（80/20）
- 使用 `StandardScaler` 进行标准化处理
- 利用 `PCA(n_components=0.999)` 降维，保留99.9%的信息量
- 输出训练集和测试集的降维结果形状，确保降维有效

### 3. 模型构建与训练
- 使用 `SVC` 构建支持向量机模型
- 在训练集上进行拟合
- 对测试集前10个样本进行预测并输出预测结果

### 4. 模型评估
- 使用 `classification_report` 输出完整分类性能评估报告，包括：
  - 精确率（Precision）
  - 召回率（Recall）
  - F1-score
  - 支持样本数量（Support）

### 5. 输出示例
```text
降维后的训练集形状: (5056, 9)
降维后的测试集形状: (1265, 9)

测试集前10个数据的预测结果: [0 0 0 0 0 0 0 0 0 0]

分类模型评价报告:
               precision    recall  f1-score   support

           0       0.99      0.98      0.99      1133
           1       0.88      0.95      0.91       132

    accuracy                           0.98      1265
   macro avg       0.94      0.97      0.95      1265
weighted avg       0.98      0.98      0.98      1265
```
## 构建基于竞标行为数据集的回归模型 `6chapter4.py`

### 1. 数据读取与特征准备
- 加载 `shill_bidding.csv` 数据集
- 去除无用字段 `"记录ID"` 和 `"拍卖ID"`
- 提取特征集 `X` 与标签列 `y = 类别`

### 2. 数据预处理
- 划分训练集与测试集（80/20）
- 使用 `MinMaxScaler` 进行标准化处理
- 利用 `PCA(n_components=0.999)` 降维，保留99.9%的信息量
- 输出训练集和测试集的降维结果形状，确保降维有效

### 3. 模型构建与训练
- 使用 `LinearRegression` 构建线性回归模型
- 在训练集上进行拟合
- 对测试集进行预测

### 4. 模型评估
- 使用以下指标评估回归模型的性能：
  - 平均绝对误差（MAE）
  - 均方误差（MSE）
  - R方值（R²）

### 5. 输出示例
```text
降维后的训练集形状: (5056, 9)
降维后的测试集形状: (1265, 9)

线性回归模型评价：
平均绝对误差 (MAE): 0.05002657255022716
均方误差 (MSE): 0.020519617158226585
R方值 (R^2): 0.7804434167333765
模型表现一般
```
## 基于APP用户行为的KMeans聚类分析类型 `7chapter.py`

### 1. 数据读取与特征准备
- 加载 `某APP用户信息数据.csv` 数据集  
- 填充字段 `不愿分享概率` 与 `愿意分享概率` 中的缺失值（默认填充为 0.0）  
- 将 `不愿分享概率` 限制在 `[0, 1]` 区间，防止异常值干扰模型  
- 将 `是否点击分享` 字段转换为数值类型：`T → 1`，`F → 0`  
- 自定义函数 `to_code` 将“用户名”的首字母转为 ASCII 编码，用作用户身份特征  
- 将 `在线时长/分钟` 转换为小时并分段（0-1小时、1-3小时、3-5小时、5小时以上）

### 2. 特征提取与降维处理
- 构建数值特征集 `X = ['不愿分享概率', '愿意分享概率', '用户名编码', '在线时长/分钟']`  
- 提取真实标签列 `y = 是否点击分享`，用于后续模型效果评估  
- 使用 `PCA(n_components=2)` 对特征集降维，便于可视化聚类分布

### 3. 模型构建与预测
- 使用 `KMeans(n_clusters=2, random_state=42)` 建立聚类模型  
- 拟合训练数据 `X` 并生成预测类别标签 `y_pred`  
- 将降维结果绘制为两个子图：一个为 KMeans 聚类结果，一个为真实标签分布

### 4. 模型评估
- 使用 `Fowlkes-Mallows Index (FMI)` 评估聚类结果与真实标签之间的匹配度  
- FMI 值的解释如下：
  - `FMI > 0.8`：聚类结果与真实标签高度匹配，效果较好  
  - `0.6 < FMI ≤ 0.8`：有一定匹配，模型效果中等  
  - `FMI ≤ 0.6`：匹配度较低，模型效果一般或较差

### 5. 输出示例
```text
 用户名     不愿分享概率   愿意分享概率   是否点击分享   在线时长/分钟   用户名编码   在线时长分段
0    James  5304407  0.014517    0.92    0.21       1     74  5小时以上
1     John  5260831  0.014398    0.04    0.01       1     74  5小时以上
...

Fowlkes-Mallows Index (FMI): 0.7235
结论：聚类结果与真实标签有一定匹配，模型效果中等。
```
